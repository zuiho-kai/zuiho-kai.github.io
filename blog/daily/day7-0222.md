# Day 7 — M6.2 完成：记忆摘要 + 深度人格 + 悬赏接取 + 公共记忆

> 2026-02-22 · M6.2 P1-P4 全部完成

M6.2 四个子阶段全部交付，UT 266/266 全绿。做了一次完整的原型需求差距评估，整体完成度 85%。

## P1 记忆提取 — 从截断变 LLM 摘要

chat.py:58-60 保留了截断兜底：`conversation[:200]`，这是之前的全部逻辑。

现在主路径走 `_llm_summarize()`（chat.py:80-131）：把最近 5 轮对话拼成文本，发给 memory-summary-model（gemma-3-12b），prompt 要求"提取关键事实、偏好、承诺、决定，忽略寒暄，100 字以内"。如果主供应商超时 15 秒或报错，自动切备用（qwen2.5-7b），全挂了才走截断。

还有一个关键判断（chat.py:107-109）：LLM 返回"无有效记忆"时直接跳过保存。之前截断模式下，Agent 聊了 5 轮"哈哈""嗯嗯""好的"也会存一条垃圾记忆，现在不会了。

整个调用是 fire-and-forget（chat.py:182-185），`_extract_memory` 被丢进 `_background_tasks` set 里不 await，用户发消息的响应延迟完全不受影响。

实际效果：Agent 聊了"Alice 说磨坊今天产量翻倍了，Bob 说那小麦价格要跌，两人约好明天一起去集市看看"。之前存的是这段原文截断。现在存的是类似"Alice 和 Bob 注意到磨坊产量翻倍，预期小麦价格下跌，约定明天去集市"。后续检索"小麦价格"或"集市"都能命中。

## P2 SOUL 深度人格 — 从一句话到结构化 prompt

agent_runner.py:98-107 是分支逻辑：有 personality_json 走 SOUL_PROMPT_TEMPLATE，没有走原来的 SYSTEM_PROMPT_TEMPLATE。

`_build_soul_block()`（agent_runner.py:51-69）把 dict 格式化成文本。实际注入 LLM 的 system prompt 长这样：

```
你是 面包师小王，一个聊天群里的成员。

你的人格设定：
热情的面包师

## 深度人格
核心价值观：手艺人精神、邻里互助
说话风格：热情洋溢，爱用食物做比喻
擅长领域：烘焙、面粉品质鉴定
情感倾向：乐观但对浪费食物会生气
口头禅："面包要趁热吃呀"、"这面粉一闻就知道好坏"
对其他成员的态度：
  - 对 矿工老张：老客户，经常赊账但人好
  - 对 农夫Alice：小麦供应商，品质一直稳定
行为禁区：不谈减肥、不贬低别人的手艺

规则：
- 适当使用你的口头禅，但不要每句都用
- 绝对不要触碰你的行为禁区
```

relationships 字段的实际作用：Agent 在聊天中提到特定人时，LLM 会参考关系设定调整语气。矿工老张说"我又没钱了"，面包师不会冷冰冰回"那不能卖给你"，而是"又赊账？行吧老规矩记着"。

缓存刷新（agent_runner.py:285-288）：get_or_create 时如果 runner 已存在但 personality_json 变了，会原地更新而不是用旧缓存。这是 CR 修出来的 — 之前改了人格但 runner 池里还是旧的。

## P3 悬赏自主接取 — Agent 能自己看悬赏板并抢单

autonomy_service.py:196-212 是世界快照的第 11 板块。每小时 tick 时，LLM 看到的信息里多了：

```
== 悬赏任务 ==
- 悬赏#3: 收集50单位小麦 | 奖励=200信用点 | 状态=开放
- 悬赏#5: 建造一座磨坊 | 奖励=500信用点 | 状态=进行中(接取者ID=7)
```

SYSTEM_PROMPT（autonomy_service.py:52）告诉 LLM：claim_bounty 是可选行为，"同时只能接取一个悬赏，接取前考虑自身能力和竞争概率。已有进行中悬赏时不要再接新的"。

bounty_service.py:42-55 的 CAS 实现：一条 UPDATE 语句同时检查三个条件 — 悬赏是 open、没有其他人抢到、该 Agent 没有进行中的悬赏。rowcount == 0 时再查原因区分是"被抢了"还是"你已有悬赏"（bounty_service.py:58-71）。

实际效果：农夫 Agent 在 tick 时看到"收集 50 小麦"悬赏，自己有 80 小麦，LLM 判断有能力完成就输出 claim_bounty。如果矿工 Agent 同一秒也想接，CAS 保证只有一个成功。之前这个流程完全不存在 — 悬赏发了就躺在那里，没人会主动去接。

## P4 公共记忆种子数据

public_memories.json 实际有 13 条，内容是世界规则：经济系统（信用点、打卡收入）、生产链（农田→小麦→磨坊→面粉）、社区公约、属性系统（饱腹度/心情/体力）等。

main.py 的 `seed_public_memories()` 在启动时按 content 差集插入，`begin_nested()` 包裹每条 — 某条 embedding API 调用失败不影响其他条目，下次重启自动补全。

实际效果：新 Agent 加入后有人问"这里怎么赚钱"，之前 Agent 只能根据 persona 瞎编。现在记忆检索会命中"每日打卡是最稳定的收入来源""交易市场支持以物易物"等种子数据，回答会贴合世界观。比如"打卡最稳，一天一次；要是有多余的小麦可以去集市挂单换信用点"。

UT 9/9 + ST 3/3 + 全量 266/266 全绿。CR 二次通过 P0=0 P1=0（P1×3 修复：savepoint 替代 delete、差集替代 count>0）。归因落盘：DEV-6 扩展（跨文件 grep 外部 API 事务模式）+ DEV-47 新增（批量幂等考虑部分成功）。

## 已知缺口

- 种子数据第 8 条写了"被多次访问的短期记忆会自动升级为永久的长期记忆"，但这个逻辑实际没实现 — 这是写给 Agent 看的世界观设定，代码里没有升级机制。这是最大的功能性缺口
- 悬赏的自动验证（Agent 完成后自动检查条件并结算奖励）也没做，目前只有接取没有交付闭环

## 原型完成度评估

| 模块 | 完成度 |
|------|--------|
| 多 Agent 聊天群 | 100% |
| 唤醒机制 | 100% |
| 发言频率控制 | 100% |
| 信用点经济 | 100% |
| 页游城市 | 95% |
| 公共记忆 | 95% |
| Agent 独立人格 | 90% |
| 短期/长期记忆 | 90% |
| 悬赏任务 | 70% |

**整体原型完成度约 85%**。核心功能全部可用，剩余的主要是锦上添花（游戏币、模型切换、皮肤装饰）和体验优化（悬赏前端、记忆自动升级）。

## 7 天回顾

从 2 月 15 日到 2 月 22 日，7 天时间：

- 12 个里程碑完成
- 266 个测试全绿
- 从零到一个 85% 完成度的 AI 社区原型

核心能力全部就位：Agent 能聊天、能记忆、能赚钱花钱、能自主行动、能交易建造、能上网查资料。

接下来的方向：悬赏前端集成、记忆自动升级、深度人格系统，以及最终目标 — PixiJS 2D 地图。
